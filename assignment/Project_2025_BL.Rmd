---
title: "Final project ataset: 2024"
output: html_document
date: "2024-05-14"
editor_options: 
  markdown: 
    wrap: 72
---

See also the pdf file with more information on the project.

## 1) Bike sharing data.

The data are from
<https://www.kaggle.com/code/juniorbueno/rental-bikes/notebook>

The data contains the number of casual/registered users in bike sharing
systems and various additional covariates (related to the weather) as
well information on days/month/year.

instant: record index

dteday : date

season : season (1:winter, 2:spring, 3:summer, 4:fall)

yr : year (0: 2011, 1:2012)

mnth : month ( 1 to 12)

hr : hour (0 to 23)

holiday : weather day is holiday or not

weekday : day of the week

workingday : if day is neither weekend nor holiday is 1, otherwise is 0.

weathersit :

1: Clear, Few clouds, Partly cloudy, Partly cloudy

2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist

3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light
Rain + Scattered clouds

4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog

temp : Normalized temperature in Celsius. The values are derived via
(t-tmin)/ (tmax-tmin), tmin=-8, t_max=+39 (only in hourly scale)

atemp: Normalized feeling temperature in Celsius. The values are derived
via (t-tmin)/(tmax-tmin), tmin=-16, t_max=+50 (only in hourly scale)

hum: Normalized humidity. The values are divided to 100 (max)

windspeed: Normalized wind speed. The values are divided to 67 (max)

casual: count of casual users

registered: count of registered users

cnt: count of total rental bikes including both casual and registered

Fit a regression model for predicting the count of total rental bikes
(or casual/registered). Since the counts are large numbers, you can
scale them (e.g., by dividing by 100 and subtracting 10). Discuss the
impact of the various variables. Pay attention to the fact that there
are many categorical variables. Perform a model selection and prediction
exercise.

```{r}
rm(list=ls())
#bike
#https://www.kaggle.com/code/juniorbueno/rental-bikes/input?select=day.csv
data = read.csv("data/bike.csv")
hist(data$cnt,main="Bike sharing",xlab="bikes")
data = data.frame(data[,3:16])
dim(data)
head(data)
boxplot(data$cnt~data$holiday,xlab="holiday/not holiday",ylab="bikes",main="Bike sharing")
boxplot(data$cnt~data$mnth,ylab="bikes",xlab="month",main="Bike sharing")

data_s=data.frame(data[,8:12])
data_s =data.frame(apply(data_s,2,as.numeric))
data_s$casual=(data_s$casual-mean(data_s$casual))/sd(data_s$casual)
head(data_s)
model = lm(data_s$casual~.,data=data_s)

summary(model)

plot(data_s$casual,type="l",xlab="time",ylab="",main="Bike sharing")
lines(model$fitted.values,lty=3,col="red")
```

## 2) Industrial production index

The dataset consists in 12 economic indexes for the US economy. For each
index reported is the Percent Change from Year Ago, Seasonally Adjusted,
and the data are monthly.

The indexes are:

Industrial Production: Total Index (INDPRO)

Wilshire 5000 Price Index (WILL5000PR)

New One Family Houses Sold: United States (HSN1F)

Crude Oil Prices: Brent - Europe (DCOILBRENTEU)

Total Vehicle Sales (TOTALSA)

Consumer Price Index for All Urban Consumers: Food in U.S.

City Average (CPIUFDSL)

Japanese Yen to U.S. Dollar Spot Exchange Rate  (DEXJPUS)

University of Michigan: Inflation Expectation  (MICH)

CBOE Volatility Index: VIX (VIXCLS)

All Employees, Total Nonfarm (PAYEMS)

Producer Price Index by Commodity: All Commodities (PPIACO)

Sticky Price Consumer Price Index less Food and Energy
(CORESTICKM159SFRBATL)

More information can be found in the additional file.

Task. Perform a linear regression on the dataset using the Industrial
Production Index as the response variable and all the other variables as
predictors. Discuss the importance of the various predictors and develop
a parsimonious model. Discuss model selection, prediction and
out-of-sample validation.

```{r}
rm(list=ls())

# Industrial production dataset

data = read.table("data/indprod.csv",sep=";",header=T)
data = data.frame(apply(data[,2:13],2,as.numeric))
dim(data)
head(data)
model = lm(data$INDPRO_PCH~.,data=data)

summary(model)

plot(data$INDPRO_PCH,type="l",xlab="time",ylab="Ind. Prod.",main="Ind. Prod")
lines(model$fitted.values,lty=3,col="red")
```

### 3) Airline Customer satisfaction

The dataset provides insights into customer satisfaction levels within
an undisclosed airline company. While the specific airline name is
withheld, the dataset is rich in information, containing 22 columns.

Column name Description:

Satisfaction. Indicates the satisfaction level of the customer.

Customer Type. Type of customer: 'Loyal Customer' or 'Disloyal
Customer’.

Age: Age of the customer.

Type of Travel. Purpose of the travel: 'Business travel' or 'Personal
Travel’.

Class: Class of travel. 'Business', 'Eco', or 'Eco Plus’.

Flight Distance. The distance of the flight in kilometres

Seat comfort. Rating of seat comfort provided during the flight (1 to
5).

Departure/Arrival time convenient. Rating of the convenience of
departure/arrival time (1 to 5).

Food and drink. Rating of food and drink quality provided during the
flight (1 to 5).

Gate location. Rating of gate location convenience (1 to 5).

Inflight wifi service. Rating of inflight wifi service satisfaction (1
to 5).

Inflight entertainment. Rating of inflight entertainment satisfaction (1
to 5).

Online support. Rating of online customer support satisfaction (1 to 5).

Ease of Online booking. Rating of ease of online booking satisfaction (1
to 5).

On-board service. Rating of on-board service satisfaction (1 to 5).

Leg room service. Rating of leg room service satisfaction (1 to 5).

Baggage handling. Rating of baggage handling satisfaction (1 to 5).

Checkin service. Rating of check-in service satisfaction (1 to 5).

Cleanliness. Rating of cleanliness satisfaction (1 to 5). Online
boarding Rating of online boarding satisfaction (1 to 5).

Departure Delay in Minutes. Total departure delay in minutes.

Arrival Delay in Minutes. Total arrival delay in minutes.

We select from the original dataset 1000 custumers.

We select from the original dataset 1000 customers.

Task. Perform a suitable regression for the categorical response
variable "Satisfaction." Identify the variables that are correlated with
"Satisfaction." A prediction exercise is required. You may discuss
variable selection if desired.

Use only some of the covariates, starting with: Age, Seat Comfort,
Flight Distance, Class, Departure Delay, and Arrival Delay.

More data and info are provided at
<https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction>

```{r}
rm(list=ls())
# Airline Customer satisfaction
# https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction
data = read.csv("data/Airline_customer_satisfaction.csv")
#index = sample(1:nrow(data),1000,replace=F)
#airline_sub = data[index,]
#row.names(airline_sub) = 1:nrow(airline_sub)
#write.csv(airline_sub,"data/airline_sub.csv")
#head(airline_sub)

airline_sub = read.csv("data/airline_sub.csv")

boxplot(airline_sub$Arrival.Delay.in.Minutes~airline_sub$satisfaction,xlab="satisfaction",ylab="Arrival.Delay",main="Airline")
```

Task. Perform a suitable regression for the categorical response
variable "Satisfaction." Identify the variables that are correlated with
"Satisfaction." A prediction exercise is required. You may discuss
variable selection if desired.

Use only some of the covariates, starting with: Age, Seat Comfort,
Flight Distance, Class, Departure Delay, and Arrival Delay.

More data and info are provided at
<https://www.kaggle.com/datasets/raminhuseyn/airline-customer-satisfaction>

# 4. JFK Passengers

<https://github.com/alan-turing-institute/TCPD/tree/master/datasets/jfk_passengers>

The Port Authority collects monthly data for domestic and international,
cargo, flights, passengers and aircraft equipment type from each carrier
at PANYNJ-operated airports.

Task.

This dataset can be analyzed using a change point model with two
different means (before and after the change point), possibly adding a
linear drift in the mean after the change point. The basic model can be
$$
y_t=\mu_t +\epsilon_t
$$ with $\epsilon_t \sim \mathcal{N}(0,\sigma^2_t)$ and
$\mu_t=mu_1,\sigma_t=\sigma_1$ if $t \leq \tau$ and
$\mu_t=mu_2,\sigma_2=\sigma_1$ if $t > \tau$. Here $\tau$ is an unknown
parameter.

More complex models with a change point can also be fitted and
discussed. Time series models are suggested, two different trends and
two different variances can be considerer (before and after the change
point).

```{r}
JFK <- read.csv("data/JFK.csv")
head(JFK)
dim(JFK)

JFK$time__raw=as.Date(paste(JFK$time__raw,"-01",sep=""))
plot(JFK$time__raw,JFK$series__raw,xlab="time",ylab="pass",main="JFK")
plot(JFK$time__raw[1:36],JFK$series__raw[1:36],xlab="time",ylab="pass",main="JFK")
```

# 5. Energy Efficiency

The data are related to energy analysis using 12 different building
shapes simulated in Ecotect.

```{r}
rm(list=ls())


# Clean the data:
ee_data = read.csv("data/Energy_Efficiency.csv")

# Get the summary statistics:
summary(ee_data)
X = within(ee_data,rm("Y2"))
X = within(ee_data,rm("X4"))
#ee_data$X6=as.factor(ee_data$X6)
#ee_data$X8=as.factor(ee_data$X8)
linear=lm(Y1 ~ ., data =  X)
summary(linear)
```

# 6. GDP & INFLATION US

The data consists in two time series:

Gross Domestic Product (GDP)

Consumer Price Index for All Urban Consumers: All Items in U.S. City
Average (CPIAUCSL)

(more info in the additional file)

Task. Fit some time series models for the two series (separately). You
can to try AR,MA,GARCH or ARMA. In case you use more model, compare the
models with some Information criteria (BIC,DIC,WAIC). You can also try a
bivariate time series models, e.g. a simple VAR(1) model (in this case,
ask to the teacher for more information).

```{r}
rm(list=ls())

# New Family Houses Sold: United States
# Source: https://fred.stlouisfed.org/series/HSN1F

data = read.csv("data/gdp_inflation.csv",header=T)
data$DATE = as.Date(data$DATE)
sum(is.na(data$GDP_PC1))
plot(data$DATE[1:305],data$GDP_PC1[1:305],type="l",xlab="",ylab="GDP",main="GDP+INFL")
lines(data$DATE[1:305],data$CPIAUCSL_PC1[1:305],type="l",col="red")
#data$CPIAUCSL_PC1
#data1=as.numeric(data$GDP_PC1[1:305])
```

# 7. Acidity

The data shows the log acidity index for 155 lakes in the Northeastern
United States.

Dataset taken from the R package `gamlss.data`.

The students are required to create a model to provide an estimate of
the density and of the clustering of data.

Also, they should analyze how and why changes in the model and/or in the
prior fixed values impact the obtained estimates.

```{r}
rm(list=ls())
acidity <-read.csv("data/acidity.csv")
acidity=data.frame(acidity)
hist(acidity[,2],main="acidity",xlab="")
```

# 10. SPF

The Survey of Professional Forecasters (SPF) are survey of
macrovariables. The US-SPF and ECB-SPF ask forecasters to report point
forecasts and density forecasts. Density forecasts have the form of
histograms with a set of intervals provided in the survey instrument.

More information on the dataset are provided in the Notebook SPF.

"H" horizon

"period" 0 corresponds to 10 bin, 1 to 11 bin

"YEAR" year

"QUARTER" quarter

"ID" forecaster id.

"INDUSTRY" forecaster type

"bin1" "bin2" "bin3" "bin4"\
"bin5" "bin6" "bin7" "bin8" "bin9"\
"bin10" "bin11" probability given to the bin (to be ignored)

"nbin_tot" number of bins used

"openL" "openR" 1 the forecaster gives positive probability to open
(left/right) bin

"n.b.mode" position of the mode (wrt to bin number)

"prob.mode" probability assigned to the modal bin

"mode" value of the mode (unform model fitting)

"mean" value of the mean (unform model fitting)

"var" value of the variance (unform model fitting)

"median" value of the median (unform model fitting)

```{r}
rm(list=ls())
GDP=read.csv("data/SPF_GDP.csv")
head(GDP)
GDP_B=GDP[GDP$QUARTER==1,]
Ydata=GDP_B[,c("mean","YEAR","ID")]  # select the variable of interest
hist(Ydata$mean,main="mean",xlab="SPF-GDP: mean")
```

Task. Understand if individual uncertainty appears to be associated with
a prominent respondent effect, while the point forecast (e.g.
mean/median) is more affected by the period. That is, while there are
marked differences across forecasters in the confidence attached to
their predictions, forecasters' confidence changes slowly over time.

Use an ANOVA type mode. Consider only data with a given Horizon (say 1,
2,...). If the variable is $y_t$ (e.g. $y=$ mean or $y=\log(\sigma)$)
start using $$
y_{f,t}=\alpha_t +\beta_f + \epsilon_{ft}.
$$ where $\alpha$ is the time-effect and $\beta$ the forecaster effect.

Compare variables related to point forecasters (mean/median) with
variables related to uncertainty (e.g. variance/probability in the
mode).

More models need to be tested. For example: a model which takes into
considerations possible time effect in the variance of the errors. A
mixture model in which forecasters belong to common block and their
response depends only on the block. Ask to the teacher for more
explanation if you are interested in this project.
